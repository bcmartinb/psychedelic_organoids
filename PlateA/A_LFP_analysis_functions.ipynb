{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba19d803-aa44-492d-977b-867955644113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription\\nAuthor: David Brin\\nFirst created: 9-10-2024\\n\\nlist of functions and descriptions to start analysis on lfp data using preprocessed lfp data by well and spike data by electrode\\n\\naltered to fit the 2 by 3 well array of plates A, B, C\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Description\n",
    "Author: David Brin\n",
    "First created: 9-10-2024\n",
    "\n",
    "list of functions and descriptions to start analysis on lfp data using preprocessed lfp data by well and spike data by electrode\n",
    "\n",
    "altered to fit the 2 by 3 well array of plates A, B, C\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5711ecc2-39ec-4a0b-8fa6-23a87726bade",
   "metadata": {},
   "source": [
    " First, import necessary libraries and define functions for analyzing lfp and spike data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eadca61-2db5-446d-a3b2-a94b8a9ebd77",
   "metadata": {},
   "source": [
    "## Imports and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51f93e2a-d2f7-48f5-8540-6b4e2d15e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matlab.engine \n",
    "import os\n",
    "import scipy.io\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import IProgress\n",
    "import scipy as sp\n",
    "from neurodsp.filt import filter_signal\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Import spectral power functions\n",
    "from neurodsp.spectral import compute_spectrum, rotate_powerlaw\n",
    "\n",
    "# Import utilities for loading and plotting data\n",
    "from neurodsp.utils import create_times\n",
    "from neurodsp.utils.download import load_ndsp_data\n",
    "from neurodsp.plts.spectral import plot_power_spectra\n",
    "from neurodsp.plts.time_series import plot_time_series\n",
    "from neurodsp.filt import filter_signal\n",
    "\n",
    "# Import the FOOOF object\n",
    "from fooof import FOOOF\n",
    "from fooof.sim.gen import gen_aperiodic\n",
    "from fooof.plts.spectra import plot_spectra\n",
    "from fooof.plts.annotate import plot_annotated_peak_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0ae73-5270-497c-8b01-4762e350c5a4",
   "metadata": {},
   "source": [
    "Loading and plotting lfp data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4197a0-f7cd-4a75-9f8d-88bd2be2302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading data\n",
    "def load_lfp(filename):\n",
    "    '''\n",
    "    function loads lfp data into one 3D array with lfp by well\n",
    "    param filename must be a preprocessed lfp file\n",
    "    returns lfp data array\n",
    "    '''\n",
    "    with h5py.File(filename, 'r') as file:\n",
    "        ds_wells_data = file['all_wells_data'][:]\n",
    "    # Since the dimensions are flipped, we need to transpose them\n",
    "    ds_wells_data = np.transpose(ds_wells_data, (2, 1, 0))\n",
    "    # Now ds_wells_data_corrected should have the correct shape\n",
    "    print(ds_wells_data.shape)\n",
    "    return ds_wells_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a3d6fc-ba13-4d2d-a6ba-64ef58fcb3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_pspectrum(sig, name = \"\", fs_ds = 100):\n",
    "    '''\n",
    "    plots one power spectrum given an array of recording values\n",
    "    Can pass in a name or change frequency\n",
    "    plots one graph and returns nothing\n",
    "    '''\n",
    "    freq_mean, psd_mean = compute_spectrum(sig, fs_ds, method='welch', avg_type='mean', nperseg=fs_ds*2)\n",
    "    plot_power_spectra([freq_mean[:]],[psd_mean[:]], [f'Welch {name}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fc1aafe-2ebe-4b3d-8126-87743193102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_pspectra(ds_wells_data, fs_ds = 100):\n",
    "    '''\n",
    "    plots all power spectra from a given data set (3D array of recordings for 6 by 8 well layout)\n",
    "    plots all graphs, returns nothing\n",
    "    '''\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 15))\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            sig = ds_wells_data[i][j]\n",
    "            freq_mean, psd_mean = compute_spectrum(sig, fs_ds, method='welch', avg_type='mean', nperseg=fs_ds*2)\n",
    "    \n",
    "            ax = axes[i, j]\n",
    "            \n",
    "            # Plot the power spectrum on the subplot\n",
    "            ax.plot(freq_mean, psd_mean)\n",
    "            ax.set_title(f'Welch- well{i}{j}')\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_yscale('log')\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab974873-6c3a-411a-91e2-4cf0a1795a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_power_windows(sig, inc, name = \"\", fs_ds = 100):\n",
    "    ''' \n",
    "    plots power spectrum of every window of given recording (sig) given the window size (inc)\n",
    "    calls plot_one_pspectrum, no returns\n",
    "    designed for recordings of 600s\n",
    "    '''\n",
    "    curr = 0\n",
    "    while curr + inc < 60000:\n",
    "        wndw = sig[curr:curr+inc]              \n",
    "        curr = curr + inc\n",
    "        freq_mean, psd_mean = compute_spectrum(wndw, fs_ds, method='welch', avg_type='mean', nperseg=fs_ds*2)\n",
    "        plot_power_spectra([freq_mean[:]], [psd_mean[:]], [f'Welch- {name} {curr} - {curr + inc}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd57d9de-567d-4d44-9524-8d9356d44467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fooof_on_windows(sig, inc, name = \"\", fs_ds = 100):\n",
    "    '''\n",
    "    similar to ds_power_windows but runs fooof on windowed recording and prints a report\n",
    "    min peak height set from 'ds_lfp_07-29-24' from peak of noise data\n",
    "    '''\n",
    "    curr = 0\n",
    "    while curr + inc < 60000:\n",
    "        wndw = sig[curr:curr+inc]               #change well with new function param (using 0,3 because of activity)\n",
    "        curr += inc\n",
    "        freq_mean, psd_mean = compute_spectrum(wndw, fs_ds, method='welch', avg_type='mean', nperseg=fs_ds*2)\n",
    "\n",
    "        fm = FOOOF(min_peak_height=0.5316, aperiodic_mode = \"knee\")\n",
    "        freq_range = [1, 50]\n",
    "        fm.report(freq_mean, psd_mean, freq_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d5d19c-601b-457f-ad08-1f6598873dc4",
   "metadata": {},
   "source": [
    "Loading and analyzing spike data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e623f4-686c-4c8d-b12b-448fdec89757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spikes(mat_file_path):\n",
    "    '''\n",
    "    loads in spike data from given path\n",
    "    returns times for each spike formatted by electrode as 6 by 8 by 4 by 4 array of spikes\n",
    "    spike_times_array[row][col][mea row][mea col][null check][spike num]\n",
    "    if the electrode has a non-null recording accessing spikes will look like spike_times_array[row][col][mea row][mea col][0][spike num]\n",
    "    if not, size of spike_times_array[row][col][mea row][mea col] will be 0\n",
    "    includes commented out option to load in waveforms (not necessary for current use)\n",
    "    '''\n",
    "    mat_data = scipy.io.loadmat(mat_file_path)\n",
    "    \n",
    "    # Display the keys in the .mat file to understand its structure\n",
    "    print(mat_data.keys())\n",
    "    \n",
    "    # Access a specific variable from the .mat file\n",
    "    spike_times = mat_data.get('spike_times')\n",
    "#    spike_waveforms = mat_data.get('spike_waveforms')\n",
    "    \n",
    "    if spike_times is not None:\n",
    "        spike_times_array = np.array(spike_times)\n",
    "    \n",
    "#    if spike_waveforms is not None:\n",
    "#        spike_waveforms_array = np.array(spike_waveforms)\n",
    "\n",
    "    return spike_times_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41370b0e-6304-4067-91c4-831870b3bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_spacial_visualization(spike_times_array):\n",
    "    '''\n",
    "    created a heatmap per well of spikes in the recording along with a blended heatmap of spikes per electrode\n",
    "    returns nothing, plots graphs\n",
    "    use load_spikes(filepath) to create spike_times_array\n",
    "    '''\n",
    "    if spike_times_array is None:\n",
    "        raise ValueError(\"Spike times data not found in the .mat file.\")\n",
    "    \n",
    "    # Initialize a 6x8 grid to store the sum of spikes in each 4x4 sub-grid\n",
    "    heatmap_data = np.zeros((2, 3))\n",
    "    \n",
    "    # Loop through each well and electrode\n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            # Initialize a 4x4 grid to store the number of spikes in each electrode\n",
    "            sub_heatmap_data = np.zeros((4, 4))\n",
    "            \n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    # Check if the electrode has data\n",
    "                    if spike_times_array[row, col, i, j] is not None and spike_times_array[row, col, i, j].size > 0:\n",
    "                        # Get the spike times for the electrode\n",
    "                        spike_times = spike_times_array[row, col, i, j][0]\n",
    "                        # Count the number of spikes and store in the sub-heatmap\n",
    "                        sub_heatmap_data[i, j] = len(spike_times)\n",
    "    \n",
    "            # Sum the number of spikes in the 4x4 sub-grid and store in the main heatmap\n",
    "            heatmap_data[row, col] = np.sum(sub_heatmap_data)\n",
    "    \n",
    "    # Plot the 6x8 heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(heatmap_data, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar(label='Number of Spikes')\n",
    "    plt.title('Spike Count Heatmap')\n",
    "    plt.xlabel('Column')\n",
    "    plt.ylabel('Row')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Find the global min and max values for the subplots\n",
    "    global_min = np.inf\n",
    "    global_max = -np.inf\n",
    "    \n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    if spike_times_array[row, col, i, j] is not None and spike_times_array[row, col, i, j].size > 0:\n",
    "                        spike_times = spike_times_array[row, col, i, j][0]\n",
    "                        count = len(spike_times)\n",
    "                        if count < global_min:\n",
    "                            global_min = count\n",
    "                        if count > global_max:\n",
    "                            global_max = count\n",
    "    \n",
    "    # Plot each 4x4 sub-heatmap in its respective 6x8 position\n",
    "    fig, axarr = plt.subplots(2, 3, figsize=(24, 18))\n",
    "    \n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            # Initialize a 4x4 grid to store the number of spikes in each electrode\n",
    "            sub_heatmap_data = np.zeros((4, 4))\n",
    "            \n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    # Check if the electrode has data\n",
    "                    if spike_times_array[row, col, i, j] is not None and spike_times_array[row, col, i, j].size > 0:\n",
    "                        # Get the spike times for the electrode\n",
    "                        spike_times = spike_times_array[row, col, i, j][0]\n",
    "                        # Count the number of spikes and store in the sub-heatmap\n",
    "                        sub_heatmap_data[i, j] = len(spike_times)\n",
    "            \n",
    "            # Plot the 4x4 sub-heatmap with unified scale\n",
    "            im = axarr[row, col].imshow(sub_heatmap_data, cmap='hot', interpolation='bilinear', vmin=global_min, vmax=global_max)\n",
    "            axarr[row, col].axis('off')\n",
    "    \n",
    "    # Add a unified colorbar for the entire figure\n",
    "    cbar = fig.colorbar(im, ax=axarr.ravel().tolist(), orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    cbar.set_label('Number of Spikes')\n",
    "    \n",
    "    plt.suptitle('Embedded Heatmaps of Spike Counts', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1235125d-f286-4226-917f-004b9e58cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_threshold_vis(spike_times_array, threshold = 20):\n",
    "    '''\n",
    "    similar to spike_spacial_visualization(spike_times_array) but colors dark green for electrodes over threshold and light for electrodes under\n",
    "    '''\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 15), constrained_layout=True)\n",
    "    \n",
    "    # Loop through each well and electrode to create subplots\n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            # Initialize an array to store electrode activity (1 for > 20 spikes, 0 otherwise)\n",
    "            electrode_activity = np.zeros((4, 4))\n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    # Check if the electrode has data and is not empty\n",
    "                    if spike_times_array[row, col, i, j] is not None and spike_times_array[row, col, i, j].size > 0:\n",
    "                        # Get the spike times for the electrode\n",
    "                        spike_times = spike_times_array[row, col, i, j][0]\n",
    "                        # Mark as active if the electrode has more than 20 spikes\n",
    "                        if len(spike_times) > threshold:\n",
    "                            electrode_activity[i, j] = 1\n",
    "    \n",
    "            # Create a subplot for the current well\n",
    "            ax = axes[row, col]\n",
    "            ax.imshow(electrode_activity, cmap='Greens', vmin=0, vmax=1)\n",
    "    \n",
    "            # Customize the subplot appearance\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_title(f'Well {row+1},{col+1}', fontsize=8)\n",
    "    \n",
    "    # Set overall plot title and show the plot\n",
    "    fig.suptitle(f'Electrode Spiking Activity Over {threshold}', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaeee4e2-fd5a-438d-a0de-62c39465ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_plot_active_spike_windows(spike_times_array, window_size, threshold = 0):\n",
    "    '''\n",
    "    takes in spike times array, window size (s), and a threshold (num spikes)\n",
    "    finds and plots the number of spikes for all windows of time per electrode with spike numbers above the threshold (default 0)\n",
    "    sorts plots by most spikes to least spikes\n",
    "    no return\n",
    "    '''\n",
    "    # Initialize a list to store spike counts and their positions\n",
    "    spike_counts = []\n",
    "    \n",
    "    # Loop through each well and electrode\n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    # Check if the electrode has data and is not empty\n",
    "                    if spike_times_array[row, col, i, j] is not None and spike_times_array[row, col, i, j].size > 0:\n",
    "                        # Get the spike times for the electrode\n",
    "                        spike_times = spike_times_array[row, col, i, j][0]\n",
    "                        # Count the number of spikes and store with position\n",
    "                        spike_counts.append((len(spike_times), (row, col, i, j)))\n",
    "    # Filter out electrodes with less than threshold spikes\n",
    "    spike_counts = [sc for sc in spike_counts if sc[0] > threshold]\n",
    "    # Sort electrodes by spike count\n",
    "    spike_counts.sort(reverse=True, key=lambda x: x[0])\n",
    "    # Find clusters of active time windows for filtered electrodes\n",
    "    active_time_windows = {}\n",
    "    for count, (row, col, i, j) in spike_counts:\n",
    "        spike_times = spike_times_array[row, col, i, j][0]\n",
    "        active_windows = []\n",
    "        # Find clusters of spike times\n",
    "        start_time = spike_times[0]\n",
    "        end_time = start_time + window_size\n",
    "        spike_count_in_window = 0\n",
    "    \n",
    "        for spike_time in spike_times:\n",
    "            if spike_time <= end_time:\n",
    "                spike_count_in_window += 1\n",
    "            else:\n",
    "                active_windows.append((start_time, end_time, spike_count_in_window))\n",
    "                start_time = spike_time\n",
    "                end_time = start_time + window_size\n",
    "                spike_count_in_window = 1    \n",
    "        # Add the last window\n",
    "        active_windows.append((start_time, end_time, spike_count_in_window))   \n",
    "        active_time_windows[(row, col, i, j)] = active_windows\n",
    "    \n",
    "    # Plot the results\n",
    "    num_plots = len(active_time_windows)\n",
    "    fig, axes = plt.subplots((num_plots + 1) // 2, 2, figsize=(20, num_plots * 2))  # Adjust figure size accordingly\n",
    "    axes = axes.flatten()\n",
    "    for idx, ((row, col, i, j), windows) in enumerate(active_time_windows.items()):\n",
    "        window_starts = [start_time for start_time, end_time, count in windows]\n",
    "        spike_counts = [count for start_time, end_time, count in windows]\n",
    "        \n",
    "        axes[idx].bar(window_starts, spike_counts, width=window_size, align='edge')\n",
    "        axes[idx].set_title(f'Electrode at Well ({row}, {col}), Sub-grid ({i}, {j})')\n",
    "        axes[idx].set_xlabel('Time (s)')\n",
    "        axes[idx].set_ylabel('Spike Count')\n",
    "        #axes[idx].axhline(y=100, color='r', linestyle='--')\n",
    "    # Hide any unused subplots\n",
    "    for ax in axes[num_plots:]:\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54743e67-bf33-4756-9797-4b730a7a1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spikes_by_well(spike_times_array):\n",
    "    '''\n",
    "    consolidates MEA recordings into one array to create a spike time array by well\n",
    "    usefull for matching organoid activity for lfp analysis\n",
    "    returns spike_times_by_well\n",
    "    '''\n",
    "    spike_times_by_well = np.empty((2, 3), dtype=object)\n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            # empty list to collect spike times for the current well\n",
    "            well_spike_times = []\n",
    "            \n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    # Check if the entry is not empty and is not a zero-dimensional array\n",
    "                    if spike_times_array[row][col][i][j].size > 0:\n",
    "                        if isinstance(spike_times_array[row][col][i][j][0], np.ndarray):\n",
    "                            well_spike_times.extend(spike_times_array[row][col][i][j][0])\n",
    "                        else:\n",
    "                            # If they are scalars, append them to the list\n",
    "                            well_spike_times.append(spike_times_array[row][col][i][j][0])\n",
    "            \n",
    "            spike_times_by_well[row, col] = np.sort(np.array(well_spike_times))\n",
    "    \n",
    "    # Now spike_times_by_well is a 6x8 array where each entry contains a sorted array of spike times for that well\n",
    "    return spike_times_by_well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a4a371-ea98-4006-b34b-d91be3d23e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_spikes_hist(spike_times_by_well, window_size, num_windows = 6, threshold = 500):\n",
    "    '''\n",
    "    plots a histogram of number of windows with a range of spikes starting at the given threshold\n",
    "    uses spike times by well for use in relation to lfp analysis\n",
    "    num_windows defaults to 6 for standard 600s recording\n",
    "    threshold defaults to 500 spikes\n",
    "    returns binary_spikes_per_window for active window analysis\n",
    "    '''\n",
    "    spikes_per_window = np.zeros((2, 3, num_windows))\n",
    "    binary_spikes_per_window = np.zeros((2, 3, num_windows))\n",
    "    \n",
    "    # Process each well to calculate spikes per window and apply threshold\n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            if spike_times_by_well[row, col].size > 0:\n",
    "                spike_times = spike_times_by_well[row, col]\n",
    "                # Create windows and count spikes per window\n",
    "                for w in range(num_windows):\n",
    "                    start_time = w * window_size\n",
    "                    end_time = (w + 1) * window_size\n",
    "                    spikes_per_window[row, col, w] = np.sum((spike_times >= start_time) & (spike_times < end_time))\n",
    "                \n",
    "                # Apply threshold to create binary array\n",
    "                binary_spikes_per_window[row, col] = spikes_per_window[row, col] > threshold\n",
    "    \n",
    "    flattened_spikes = spikes_per_window.flatten()\n",
    "    flattened_binary_flags = binary_spikes_per_window.flatten()  \n",
    "    # Filter the spikes that are above the threshold\n",
    "    spikes_above_threshold = flattened_spikes[flattened_binary_flags == 1]  \n",
    "    # Plot the histogram of spikes per window for those above the threshold\n",
    "    plt.hist(spikes_above_threshold, bins=50, edgecolor='black')\n",
    "    plt.xlabel('Number of Spikes per Window (Above Threshold)')\n",
    "    plt.ylabel('Number of Windows')\n",
    "    plt.title('Histogram of Number of Spikes per Window (Above Threshold)')\n",
    "    plt.show()\n",
    "    # binary_spikes_per_window is now a 6x8x6 array where each entry is 0 or 1 based on the threshold\n",
    "    return binary_spikes_per_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f4689-caaa-4aad-8bde-eb1c90e134de",
   "metadata": {},
   "source": [
    "Active window analysis for lfp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c00361e-3e43-4d75-a74b-f3c29ebd6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fooof_wind_thresh(binary_activity, ds_wells_data, window_size, num_windows = 6, fs_ds = 100):\n",
    "    '''\n",
    "    creates and reports a fooof object on the data from the active window\n",
    "    binary_activity: use returned value from plot_num_spikes_hist\n",
    "    window_size: size of window\n",
    "    num_windows defaults to 6 and fs_ds to 100 as previously done\n",
    "    no return, prints and plots fooof report\n",
    "    '''\n",
    "    print(f\"fitting all {window_size}s active windows per well\")\n",
    "    \n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            for w in range(num_windows):\n",
    "                if binary_activity[row, col, w] == 1:\n",
    "                    start_time = w * window_size\n",
    "                    end_time = (w + 1) * window_size\n",
    "    \n",
    "                    print(f\"fitting well {row},{col} {start_time}:{end_time}\")\n",
    "                    sig = ds_wells_data[row][col][start_time*fs_ds:end_time*fs_ds]              \n",
    "                    freq_mean, psd_mean = compute_spectrum(sig, fs_ds, method='welch', avg_type='mean', nperseg=fs_ds*2)\n",
    "            \n",
    "                    fm = FOOOF(min_peak_height=0.5316, aperiodic_mode = \"knee\")\n",
    "                    freq_range = [1, 50]\n",
    "                    fm.report(freq_mean, psd_mean, freq_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4af76bec-093a-454b-95e9-29fdcf53a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndsp_wind_thresh(binary_activity, ds_wells_data, window_size, num_windows = 6, fs_ds = 100):\n",
    "    '''\n",
    "    same as fooof_wind_thresh but uses the neurodsp method plot_power_spectra instead of fooof\n",
    "    '''\n",
    "    print(f\"fitting all {window_size}s active windows per well\")\n",
    "    \n",
    "    for row in range(2):\n",
    "        for col in range(3):\n",
    "            for w in range(num_windows):\n",
    "                if binary_activity[row, col, w] == 1:\n",
    "                    start_time = w * window_size\n",
    "                    end_time = (w + 1) * window_size\n",
    "    \n",
    "                    print(f\"fitting well {row},{col} {start_time}:{end_time}\")\n",
    "                    sig = ds_wells_data[row][col][start_time*fs_ds:end_time*fs_ds]              \n",
    "                    freq_mean, psd_mean = compute_spectrum(sig, fs_ds, method='welch', avg_type='mean', nperseg=fs_ds)\n",
    "                    plot_power_spectra([freq_mean[:]], [psd_mean[:]], [f'Welch- well[{row},{col}] {start_time}:{end_time}'])      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f9068-43c1-4a71-9470-da9f9a7f200c",
   "metadata": {},
   "source": [
    "Variation of FoooF parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6498a61-2605-496a-83db-34c9a0f99b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_fm_array(ds_wells_data, fs_ds = 100):\n",
    "    '''\n",
    "    creates an array of fooof objects based on given well data for parameter analysis by well\n",
    "    returns the array of fooof objects\n",
    "    '''\n",
    "    fm_array = np.empty((2, 3), dtype=object)\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            sig = ds_wells_data[i][j]\n",
    "            freq_mean, psd_mean = compute_spectrum(sig, fs_ds, method='welch', avg_type='mean', nperseg=fs_ds*2)\n",
    "            # Initialize a FOOOF object\n",
    "            fm = FOOOF(min_peak_height=0.5316, aperiodic_mode = \"knee\")\n",
    "            fm_array[i, j] = fm\n",
    "            # Set the frequency range to fit the model\n",
    "            freq_range = [2, 50]\n",
    "            \n",
    "            # Report: fit the model, print the resulting parameters, and plot the reconstruction\n",
    "            fm.fit(freq_mean, psd_mean, freq_range)\n",
    "\n",
    "    return fm_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f337f630-39c8-4d64-85d7-6952a6d9dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_heatmap(fm_array):\n",
    "    '''\n",
    "    uses a heatmap to plot each parameter in a spacial distribution view\n",
    "    takes in fm_array (array of fooof objects)\n",
    "    no return, just plots\n",
    "    '''\n",
    "    # Extract the 3 aperiodic parameters and R^2 values into separate 6x8 arrays\n",
    "    offsets = np.zeros((2, 3))\n",
    "    knees = np.zeros((2, 3))\n",
    "    exponents = np.zeros((2, 3))\n",
    "    r_squared_values = np.zeros((2, 3))\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            offsets[i, j] = fm_array[i, j].aperiodic_params_[0]\n",
    "            knees[i, j] = fm_array[i, j].aperiodic_params_[1]\n",
    "            exponents[i, j] = fm_array[i, j].aperiodic_params_[2]\n",
    "            r_squared_values[i, j] = fm_array[i, j].r_squared_\n",
    "    \n",
    "    # Create a function to plot heatmaps\n",
    "    def plot_heatmap(data, title, cbar_label):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(data, annot=True, cmap='viridis', cbar_kws={'label': cbar_label})\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Well Column')\n",
    "        plt.ylabel('Well Row')\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot each heatmap\n",
    "    plot_heatmap(offsets, 'Aperiodic Offsets', 'Value')\n",
    "    plot_heatmap(knees, 'Aperiodic Knees', 'Value')\n",
    "    plot_heatmap(exponents, 'Aperiodic Exponents', 'Value')\n",
    "    plot_heatmap(r_squared_values, 'R-Squared Values', 'R^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9e32d21-0d63-4de4-9932-ffd4b3ce5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example dose grid for the following functions (define dose grid in running notebook for customized experiment):\n",
    "dose_grid = np.array([\n",
    "    ['10uM', '10uM', '10uM', '20uM', '20uM', '20uM', 'Vehicle', 'Vehicle'],\n",
    "    ['10uM', '10uM', '10uM', '20uM', '20uM', '20uM', 'Vehicle', 'Vehicle'],\n",
    "    ['10uM', '10uM', '10uM', '20uM', '20uM', '20uM', 'Vehicle', 'Vehicle'],\n",
    "    ['10uM', '10uM', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank'],\n",
    "    ['Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank'],\n",
    "    ['Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06a95a25-d7e4-4a8d-8d62-6d06310ab306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variability(fm_array, dose_grid):\n",
    "    '''\n",
    "    plots the standard deviation of the aperiodic paramters from given fm_array\n",
    "    doesn't plot knees for scale issues\n",
    "    lables should be changed according to 'dose_grid'\n",
    "    returns nothing, plots graphs\n",
    "    '''\n",
    "    # Calculate standard deviation for each parameter based on the dose\n",
    "    def calculate_variability(param_array, dose_grid, dose):\n",
    "        mask = dose_grid == dose\n",
    "        return np.nanstd(param_array[mask])\n",
    "        \n",
    "    offsets = np.zeros((2, 3))\n",
    "    knees = np.zeros((2, 3))\n",
    "    exponents = np.zeros((2, 3))   \n",
    "    r_squared_values = np.zeros((2, 3))\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            offsets[i, j] = fm_array[i, j].aperiodic_params_[0]\n",
    "            knees[i, j] = fm_array[i, j].aperiodic_params_[1]\n",
    "            exponents[i, j] = fm_array[i, j].aperiodic_params_[2]\n",
    "            r_squared_values[i, j] = fm_array[i, j].r_squared_\n",
    "    \n",
    "    variability_eGFP = {\n",
    "        'Aperiodic 1': calculate_variability(offsets, dose_grid, 'eGFP'),\n",
    "        #'Aperiodic 2': calculate_variability(knees, dose_grid, '10uM'),\n",
    "        'Aperiodic 3': calculate_variability(exponents, dose_grid, 'eGFP'),\n",
    "    }\n",
    "    \n",
    "    variability_CheRiff = {\n",
    "        'Aperiodic 1': calculate_variability(offsets, dose_grid, 'CheRiff'),\n",
    "        #'Aperiodic 2': calculate_variability(knees, dose_grid, '20uM'),\n",
    "        'Aperiodic 3': calculate_variability(exponents, dose_grid, 'CheRiff'),\n",
    "    }\n",
    "\n",
    "    def variability(variability_dict, title):\n",
    "        categories = list(variability_dict.keys())\n",
    "        values = list(variability_dict.values())\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.barplot(x=categories, y=values, palette=\"viridis\")\n",
    "        plt.title(title)\n",
    "        plt.ylabel('Standard Deviation')\n",
    "        plt.show()\n",
    "\n",
    "    variability(variability_eGFP, 'Variability in eGFP')\n",
    "    variability(variability_CheRiff, 'Variability in CheRiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b459ba04-70a5-447c-a879-72fba0f1fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aperiodic_boxplot(fm_array,  dose_grid):\n",
    "    '''\n",
    "    plots boxplots based on the aperiodic parameter lists extracted from fm_array and uses dose_grid for plotting \n",
    "    returns nothing, plots graphs\n",
    "    '''\n",
    "    dose_labels = []\n",
    "    aperiodic_param_1_list = []\n",
    "    aperiodic_param_2_list = []\n",
    "    aperiodic_param_3_list = []\n",
    "    offsets = np.zeros((2, 3))\n",
    "    knees = np.zeros((2, 3))\n",
    "    exponents = np.zeros((2, 3))\n",
    "    #extract aperiodic parameter arrays\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            offsets[i, j] = fm_array[i, j].aperiodic_params_[0]\n",
    "            knees[i, j] = fm_array[i, j].aperiodic_params_[1]\n",
    "            exponents[i, j] = fm_array[i, j].aperiodic_params_[2]\n",
    "    \n",
    "    # Loop through each well and collect data\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            dose = dose_grid[i, j]\n",
    "            #if dose in grouped_params:\n",
    "                # Ensure that aperiodic parameters are not None or empty\n",
    "            if offsets[i, j] is not None and knees[i, j] is not None and exponents[i, j] is not None:\n",
    "                dose_labels.append(dose)\n",
    "                aperiodic_param_1_list.append(offsets[i, j])\n",
    "                aperiodic_param_2_list.append(knees[i, j])\n",
    "                aperiodic_param_3_list.append(exponents[i, j])\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Dose': dose_labels,\n",
    "        'Offsets': aperiodic_param_1_list,\n",
    "        'Knees': aperiodic_param_2_list,\n",
    "        'Exponents': aperiodic_param_3_list\n",
    "    })\n",
    "    \n",
    "    # Plotting boxplots for each aperiodic parameter\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    for idx, param in enumerate(['Offsets', 'Knees', 'Exponents'], 1):\n",
    "        plt.subplot(1, 3, idx)\n",
    "        sns.boxplot(x='Dose', y=param, data=df)\n",
    "        plt.title(f'{param} by Dose')\n",
    "        plt.xlabel('Dose')\n",
    "        plt.ylabel(param)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28b1065c-da5d-4bc5-846c-a6bc7a4efb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peak_boxplot(fm_array,  dose_grid):\n",
    "    '''\n",
    "    plots boxplots based on the peak parameter lists extracted from fm_array and uses dose_grid for plotting \n",
    "    returns nothing, plots graphs\n",
    "    '''\n",
    "    peak_params = []\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            peak_param = fm_array[i, j].peak_params_\n",
    "            if peak_param is not None and len(peak_param) > 0:\n",
    "                peak_params.append(peak_param)\n",
    "    peak_param_1_list = []\n",
    "    peak_param_2_list = []\n",
    "    peak_param_3_list = []\n",
    "    \n",
    "    # Extract the peak parameters\n",
    "    for params in peak_params:\n",
    "        peak_param_1_list.append(params[0, 0])\n",
    "        peak_param_2_list.append(params[0, 1])\n",
    "        peak_param_3_list.append(params[0, 2])\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df_peak = pd.DataFrame({\n",
    "        'center frequency': peak_param_1_list,\n",
    "        'power': peak_param_2_list,\n",
    "        'bandwidth': peak_param_3_list\n",
    "    })\n",
    "    \n",
    "    # Plotting boxplots for each peak parameter\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    for idx, param in enumerate(['center frequency', 'power', 'bandwidth'], 1):\n",
    "        plt.subplot(1, 3, idx)\n",
    "        sns.boxplot(y=param, data=df_peak)\n",
    "        plt.title(f'{param} Distribution')\n",
    "        plt.xlabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade9069-fb92-4ac9-8e2c-517d2d69f537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
